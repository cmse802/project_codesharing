{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Using Statistical Models in User Clickstream data</center>\n",
    "\n",
    "<center>by Jiaoping Chen</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several approaches have been adopted to model user engagements. In the following, I introduce some of the works related to student dropout and performance prediction using sequential data (eg, a student's clickstream data on online systems). Specifically, two mainstream methods for handling sequential data are 1) statistical-based Markov models and 2) machine-learning-based Deep learning. I would introduce the former one, Markov models, in this report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic **Markov Chain models** are popular stochastic models to handle the sequential data using a discrete-time Markov Chain. For example, the user's clickstream can be represented by a sequence of \"states\", and each state corresponds to a page type that the user clicks such as home, content, assignment on D2L. However, this approach assumes that future states depend only on the current state, not on previous events (called \"Markov property\"). Thus, Markov models are good starting points to model sequential data but have limited performance for prediction tasks due to short-time memories.\n",
    "\n",
    "**Higher-order Markov chains** relax the short-memory limits of Markov Chains by considering more histories/previous states. It can also capture clickstream patterns more accurately and then improve predictive performance [1, 2]. **Variable-length Markov chains** make the higher-order Markov chains more flexible by allowing for variable-length history [3]. Both approaches have a better predictive performance for future users' states, but they suffer from the exponential increase in computation costs due to the rise of state space. Especially, fast predictions are required in real applications to select corresponding motivated strategies, such as inferring a student's risk of dropout in real-time.\n",
    "\n",
    "In many cases, the events we are interested in are hidden, or we cannot observe them directly. For example, we don't observe a person's health condition. Rather, we see reports from physical evaluations that must infer the latent health condition. A **Hidden Markov model (HMM)** is a first-order discrete-time Markov chain model that modeling the user's latent states using observed events. HMMs assume that the currently observed outcome (eg, \"visit the home page\") depends on the current latent state of mind (eg, \"goal-directed\" or \"exploratory\" search)[4]. In other words, the observed behavior events might reflect a user's latent goals, which helps to predict future behaviors. The goal of HMM is to learn hidden states using observed sequential events. \n",
    "\n",
    "\n",
    "Modeling HMMs requires three components: 1) an initial probability distribution, 2) a transition probability matrix $A_{it}$, and 3) an emission matrix. The hidden state of a user $i$ at time $t$ is denoted by $S_{it}$, where $S_{it} = 1, 2, .. K$, and $K$ is the total number of hidden states.\n",
    "\n",
    "- (1) First, we have to model an **initial probability distribution** over hidden states $\\phi_{j}$ that account for the probablity of a user starting their hidden state sequences at the latent state $j$. Some states $j$ may have $\\phi_{j} = 0$, meaning that they cannot be initial states. Also, $\\sum_{j=1}^{K}\\phi_{j} = 1$.\n",
    "\n",
    "- (2) Second, we can account for the evolution of states using a user and time-specific state **transition probability matrix**, denoted as\n",
    "$$A_{it} = \\begin{bmatrix} a_{it,1,1} & ... & a_{it,1,K} \\\\ ... & ... & ... \\\\ a_{it,K,1} & ... & a_{it,K,K} \\end{bmatrix}$$ \n",
    "where $a_{it,s,s'}$ is the probability that user $i$ transitions from state $s$ at time $t$ to state $s'$ at time $t+1$. Each state $a_{ij}$ represents the probability of moving from state $i$ to state $j$, s.t. for any $i$, $\\sum_{j=1}^{K}a_{ij} = 1$.\n",
    "\n",
    "- (3) The sequence of observations of a user $i$ at time $t$ is denoted by $O_{it}$, where $O_{it} = 1, 2,.. V$ and $V$ is the total number of observed states. Thus, we can generate a sequence of **emission probabilities**, denoted as  $P(O_{it} | S_{it}=s)$, that expressing the probability of an observed $O_{it}$ being generated from a state $S_{it}$. This conditional distribution can be modeled by various statistical distributions, such as a negative binomial distribution (**add reference Luyan here**).\n",
    "\n",
    "After generating three components, we can write down the likelihood function and estimate the parameters of HMM (all parameters within the above three components) using a forward-backward algorithm. Given the observed sequences, if we want to get the sequence of hidden states, we can utilize the Viterbi algorithm to fast obtain the patterns.\n",
    "\n",
    "**An Example for HMM**\n",
    "\n",
    "For example, a student's clickstream on D2L can be represented by a sequence of observed outcomes (\"home\"-\"course_01\"-\"assignment\"-\"home\"-\"course_02\"-\"lecture1\"-\"lecture2\"-....). We can assume there are three hidden states exist that drive the observed behaviors: goal-target-for-assignment, goal-target-for-learning, exploration. Then, we can represent a 3*1 initial probability matrix, and a 3*3 transition matrix for each user $i$ at time $t$. Besides, we can also represent the emission probability for each user $i$ at time $y$, such as $P(\"home\"|\"goal-target-for-assignment\")$, $P(\"home\"|\"goal-target-for-learning\")$ and $P(\"course_{01}\"|\"exploration\")$. After that, we can compute the likelihood function using observed sequences to estimate parameters within the initial matrix, transition matrix, and emission probabilities. Therefore, we can predict future hidden states as well as obtain previously hidden state sequences, given previously observed outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# References\n",
    "\n",
    "[1]Borges, Jose, and Mark Levene. \"Data mining of user navigation patterns.\" In International Workshop on Web Usage Analysis and User Profiling, pp. 92-112. Springer, Berlin, Heidelberg, 1999. \n",
    "\n",
    "[2]Lakshminarayan, Choudur, Ram Kosuru, and Meichun Hsu. \"Modeling complex clickstream data by stochastic models: Theory and methods.\" In Proceedings of the 25th International Conference Companion on World Wide Web, pp. 879-884. 2016.\n",
    "\n",
    "[3]Borges, Jose, and Mark Levene. \"Evaluating variable-length markov chain models for analysis of user web navigation sessions.\" IEEE Transactions on Knowledge and Data Engineering 19, no. 4 (2007): 441-452.\n",
    "\n",
    "[4]Moe, Wendy W. \"Buying, searching, or browsing: Differentiating between online shoppers using in-store navigational clickstream.\" Journal of consumer psychology 13, no. 1-2 (2003): 29-39."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
